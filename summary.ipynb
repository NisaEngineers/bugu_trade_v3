{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e3c750-9df9-46bf-8897-d376d7f3cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bugu_machine_learning import RidgeModel, LinearRegressionModel, DecisionTree, ExtraTrees, GradientBoosting, AdaBoost_Simple, Bagging_Simple, RandomForest_Simple, TensorflowNN, ada_boost_r, random_forest_r\n",
    "from bugu_trend_confirmation_indicator import analyze_market_trend\n",
    "from bugu_technical_indicators import dynamic_trading_with_key_level, MachineLearningSupertrend, HalfTrendRegression, BuySellSignal, HeikinAshiSignals, TargetTrend, SignalGenerator, SwingHighLowAnalyzer, FRAMAChannel, AbnormalCandleDetector, OrderBlocksDetector, PsychoSignal, PrevGood, PivotPoints\n",
    "from bugu_real_trade import MT5DataFetcher\n",
    "from bugu_news_sentiment import NewsSentimentAnalyzer\n",
    "from bugu_volatility_model import ArchModels\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a773e0-e1bc-4af1-9ba6-ba5959dd57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write output to file and print it\n",
    "def write_output_to_file(output, filename):\n",
    "    # Ensure the \"analysis\" folder exists\n",
    "    if not os.path.exists(\"analysis\"):\n",
    "        os.makedirs(\"analysis\")\n",
    "    \n",
    "    filepath = os.path.join(\"analysis\", filename)\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(output)\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d324103-d172-468f-8a02-1b7910c5d610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded H1 data for BTCUSDm\n",
      "Downloaded H4 data for BTCUSDm\n",
      "Downloaded D1 data for BTCUSDm\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68cb898d-62ba-49f2-bc71-a15341677321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bugu_machine_learning import RidgeModel, LinearRegressionModel, DecisionTree, ExtraTrees, GradientBoosting, AdaBoost_Simple, Bagging_Simple, RandomForest_Simple, TensorflowNN, ada_boost_r, random_forest_r\n",
    "from bugu_trend_confirmation_indicator import analyze_market_trend\n",
    "from bugu_technical_indicators import dynamic_trading_with_key_level, MachineLearningSupertrend, HalfTrendRegression, BuySellSignal, HeikinAshiSignals, TargetTrend, SignalGenerator, SwingHighLowAnalyzer, FRAMAChannel, AbnormalCandleDetector, OrderBlocksDetector, PsychoSignal, PrevGood, PivotPoints\n",
    "from bugu_real_trade import MT5DataFetcher\n",
    "from bugu_news_sentiment import NewsSentimentAnalyzer\n",
    "from bugu_volatility_model import ArchModels\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to write output to file and print it\n",
    "def write_output_to_file(output, filename):\n",
    "    # Ensure the \"analysis\" folder exists\n",
    "    if not os.path.exists(\"analysis\"):\n",
    "        os.makedirs(\"analysis\")\n",
    "    \n",
    "    filepath = os.path.join(\"analysis\", filename)\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(output)\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        print(f.read())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "#print(csv_files)\n",
    "\n",
    "api_key = '5cb98f18e3224b98bc1ddef0446b4dc0'\n",
    "symbol = \"BTCJPYm\"\n",
    "timeframes = ['H1','H4', 'D1']\n",
    "data_fetcher = MT5DataFetcher(symbol, timeframes)\n",
    "data_fetcher.initialize_mt5()\n",
    "csv_files = data_fetcher.fetch_data()\n",
    "output = f'''\n",
    "Do a own research on {symbol.replace(\"m\",\"\")} market news analysis, sentiment and other fundamentals.\n",
    "'''\n",
    "\n",
    "full_text = \" \"\n",
    "output += \"\\n\"\n",
    "# Current Data Section\n",
    "print(f\"{'#'*10} Latest data {'#'*10}\")\n",
    "output += f\"{'#'*10} Latest data {'#'*10}\\n\"\n",
    "for files in csv_files:\n",
    "    #i = int(input(\"Enter timeframe: [0: M30; 1: H1, 2: H4, 3:D1, 4: W1]\"))\n",
    "    data = pd.read_csv(f\"{files}\")\n",
    "    # Access the data from the DataFrame, not the filename string\n",
    "    current_high = data['high'].iloc[-1]\n",
    "    current_close = data['close'].iloc[-1]\n",
    "    current_low = data['low'].iloc[-1]\n",
    "    print(f\"Current High: {current_high}, Close: {current_close}, Low: {current_low}\")\n",
    "    output += f\"Current High: {current_high}, Close: {current_close}, Low: {current_low}\\n\"\n",
    "    \n",
    "    \n",
    "    # News Analsysis Section\n",
    "    data = pd.read_csv(f\"{files}\")\n",
    "    symbol_news = symbol.replace(\"USDm\",\"\")\n",
    "    page_size = 10\n",
    "    news_analyzer = NewsSentimentAnalyzer(api_key, symbol=symbol_news, page_size=page_size)\n",
    "    import io\n",
    "    import sys\n",
    "    buffer = io.StringIO()\n",
    "    sys.stdout = buffer\n",
    "    news_analyzer.run_analysis()\n",
    "    #print(news_analyzer.run_analysis())\n",
    "    news_output = buffer.getvalue()\n",
    "    print(news_analyzer.run_analysis())\n",
    "    sys.stdout = sys.__stdout__\n",
    "    output += news_output\n",
    "    plot=False\n",
    "    csv_files = data_fetcher.fetch_data()\n",
    "    files = files\n",
    "    output += f\"{'-'*10} {files} {'-'*10}\\n\"\n",
    "    #data = pd.read_csv(csv_files[0]) \n",
    "    print(f\"{'-'*10} Indicators Outputs {'-'*10}\")\n",
    "    output += f\"{'-'*10} Indicators Outputs {'-'*10}\\n\"\n",
    "    \n",
    "    print(f\"{'.'*5} half_trend_regression {'.'*5}\")\n",
    "    output += f\"{'.'*5} half_trend_regression {'.'*5}\\n\"\n",
    "    data = pd.read_csv(f'{files}')\n",
    "    data['date'] = pd.to_datetime(data['time'])\n",
    "    ht_regression = HalfTrendRegression(data)\n",
    "    df, future_trend = ht_regression.half_trend_regression(plot=plot)\n",
    "    print(f\"The future trend is: {future_trend}\")\n",
    "    df.drop(columns=['time.1', 'open', 'high', 'low', 'close', 'tick_volume', 'real_volume'], inplace=True)\n",
    "    last_row_ht = df.iloc[-1]\n",
    "    # Print all columns from the last row in one go for HalfTrendRegression\n",
    "    print(last_row_ht)\n",
    "    # Append all columns output to the `output` variable in one go for HalfTrendRegression\n",
    "    output += f\"{last_row_ht}\"\n",
    "\n",
    "    print(f\"{'.'*5} BuySellSignal {'.'*5}\")\n",
    "    output += f\"{'.'*5} BuySellSignal {'.'*5}\\n\"\n",
    "    # Example usage\n",
    "    data = pd.read_csv(f'{files}')\n",
    "    analyzer = BuySellSignal(data)\n",
    "    trend = analyzer.analyze_trend(plot=plot)\n",
    "    print(f\"The current trend is: {trend}\")\n",
    "    data = analyzer.generate_signals()\n",
    "    data.drop(columns=['time.1', 'open', 'high', 'low', 'close', 'tick_volume', 'real_volume'], inplace=True)\n",
    "    last_row_bs = data.iloc[-1]\n",
    "    last_row_ht = last_row_bs\n",
    "    print(f\"\"\"time: {last_row_ht['time']}, spread: {last_row_ht['spread']}, smrng1: {last_row_ht['smrng1']}, smrng2: {last_row_ht['smrng2']},\n",
    "    smrng: {last_row_ht['smrng']}, sma: {last_row_ht['sma']}, filt: {last_row_ht['filt']}, upward: {last_row_ht['upward']},\n",
    "    downward: {last_row_ht['downward']}, longCond: {last_row_ht['longCond']}, shortCond: {last_row_ht['shortCond']}, CondIni: {last_row_ht['CondIni']},\n",
    "    long: {last_row_ht['long']}, short: {last_row_ht['short']}, bullishCandle: {last_row_ht['bullishCandle']}, bearishCandle: {last_row_ht['bearishCandle']},\n",
    "    rsi: {last_row_ht['rsi']}, isRSIOB: {last_row_ht['isRSIOB']}, isRSIOS: {last_row_ht['isRSIOS']}, tradeSignal: {last_row_ht['tradeSignal']}, signal: {last_row_ht['signal']}\n",
    "    \"\"\")\n",
    "    # Append all columns output to the `output` variable in one go for BuySellSignal\n",
    "    output += f\"\"\"time: {last_row_ht['time']}, spread: {last_row_ht['spread']}, smrng1: {last_row_ht['smrng1']}, smrng2: {last_row_ht['smrng2']},\n",
    "    smrng: {last_row_ht['smrng']}, sma: {last_row_ht['sma']}, filt: {last_row_ht['filt']}, upward: {last_row_ht['upward']},\n",
    "    downward: {last_row_ht['downward']}, longCond: {last_row_ht['longCond']}, shortCond: {last_row_ht['shortCond']}, CondIni: {last_row_ht['CondIni']},\n",
    "    long: {last_row_ht['long']}, short: {last_row_ht['short']}, bullishCandle: {last_row_ht['bullishCandle']}, bearishCandle: {last_row_ht['bearishCandle']},\n",
    "    rsi: {last_row_ht['rsi']}, isRSIOB: {last_row_ht['isRSIOB']}, isRSIOS: {last_row_ht['isRSIOS']}, tradeSignal: {last_row_ht['tradeSignal']}, signal: {last_row_ht['signal']}\n",
    "    \"\"\"\n",
    "    print(f\"{'.'*5} SignalGenerator {'.'*5}\")\n",
    "    output += f\"{'.'*5} SignalGenerator {'.'*5}\\n\"\n",
    "    df = pd.read_csv(f'{files}')\n",
    "    signal_generator = SignalGenerator(df)\n",
    "    trend = signal_generator.analyze_trend(plot=plot)\n",
    "    print(f\"The current trend is: {trend}\")\n",
    "    report = signal_generator.generate_signals()\n",
    "    report.drop(columns=['time.1', 'open', 'high', 'low', 'close', 'tick_volume', 'real_volume'], inplace=True)\n",
    "    last_row_sg = report.iloc[-1]\n",
    "    # Print all columns from the last row in one go for SignalGenerator\n",
    "    print(f\"\"\"\n",
    "    time: {last_row_sg['time']}, spread: {last_row_sg['spread']}, hlc3: {last_row_sg['hlc3']}, rsi: {last_row_sg['rsi']},\n",
    "    smoothed_rsi: {last_row_sg['smoothed_rsi']}, highest_high: {last_row_sg['highest_high']}, lowest_low: {last_row_sg['lowest_low']},\n",
    "    williams_r: {last_row_sg['williams_r']}, smoothed_williams_r: {last_row_sg['smoothed_williams_r']}, volume_average: {last_row_sg['volume_average']},\n",
    "    recent_volume_average: {last_row_sg['recent_volume_average']}, is_green_candle: {last_row_sg['is_green_candle']}, is_red_candle: {last_row_sg['is_red_candle']},\n",
    "    is_high_volume_b1: {last_row_sg['is_high_volume_b1']}, is_high_volume_b2: {last_row_sg['is_high_volume_b2']}, is_high_volume_s1: {last_row_sg['is_high_volume_s1']},\n",
    "    is_high_volume_s2: {last_row_sg['is_high_volume_s2']}, ema_short: {last_row_sg['ema_short']}, ema_long: {last_row_sg['ema_long']},\n",
    "    bullish_ema_cross: {last_row_sg['bullish_ema_cross']}, bearish_ema_cross: {last_row_sg['bearish_ema_cross']}, atr: {last_row_sg['atr']},\n",
    "    long_stop: {last_row_sg['long_stop']}, short_stop: {last_row_sg['short_stop']}, psar: {last_row_sg['psar']}, psar_dir: {last_row_sg['psar_dir']},\n",
    "    sell_signal: {last_row_sg['sell_signal']}, bull_weight_2: {last_row_sg['bull_weight_2']}, bear_weight_2: {last_row_sg['bear_weight_2']},\n",
    "    bull_signal_2: {last_row_sg['bull_signal_2']}, bear_signal_2: {last_row_sg['bear_signal_2']}, rsi_williams_r_bull: {last_row_sg['rsi_williams_r_bull']},\n",
    "    rsi_williams_r_bear: {last_row_sg['rsi_williams_r_bear']}, b1_buy: {last_row_sg['b1_buy']}, b2_buy: {last_row_sg['b2_buy']},\n",
    "    b2_strong_buy: {last_row_sg['b2_strong_buy']}, s1_sell: {last_row_sg['s1_sell']}, s2_sell: {last_row_sg['s2_sell']},\n",
    "    s2_strong_sell: {last_row_sg['s2_strong_sell']}, signal: {last_row_sg['signal']}\n",
    "    \"\"\")\n",
    "    # Append all columns output to the `output` variable in one go for SignalGenerator\n",
    "    output += f\"\"\"\n",
    "    time: {last_row_sg['time']}, spread: {last_row_sg['spread']}, hlc3: {last_row_sg['hlc3']}, rsi: {last_row_sg['rsi']},\n",
    "    smoothed_rsi: {last_row_sg['smoothed_rsi']}, highest_high: {last_row_sg['highest_high']}, lowest_low: {last_row_sg['lowest_low']},\n",
    "    williams_r: {last_row_sg['williams_r']}, smoothed_williams_r: {last_row_sg['smoothed_williams_r']}, volume_average: {last_row_sg['volume_average']},\n",
    "    recent_volume_average: {last_row_sg['recent_volume_average']}, is_green_candle: {last_row_sg['is_green_candle']}, is_red_candle: {last_row_sg['is_red_candle']},\n",
    "    is_high_volume_b1: {last_row_sg['is_high_volume_b1']}, is_high_volume_b2: {last_row_sg['is_high_volume_b2']}, is_high_volume_s1: {last_row_sg['is_high_volume_s1']},\n",
    "    is_high_volume_s2: {last_row_sg['is_high_volume_s2']}, ema_short: {last_row_sg['ema_short']}, ema_long: {last_row_sg['ema_long']},\n",
    "    bullish_ema_cross: {last_row_sg['bullish_ema_cross']}, bearish_ema_cross: {last_row_sg['bearish_ema_cross']}, atr: {last_row_sg['atr']},\n",
    "    long_stop: {last_row_sg['long_stop']}, short_stop: {last_row_sg['short_stop']}, psar: {last_row_sg['psar']}, psar_dir: {last_row_sg['psar_dir']},\n",
    "    sell_signal: {last_row_sg['sell_signal']}, bull_weight_2: {last_row_sg['bull_weight_2']}, bear_weight_2: {last_row_sg['bear_weight_2']},\n",
    "    bull_signal_2: {last_row_sg['bull_signal_2']}, bear_signal_2: {last_row_sg['bear_signal_2']}, rsi_williams_r_bull: {last_row_sg['rsi_williams_r_bull']},\n",
    "    rsi_williams_r_bear: {last_row_sg['rsi_williams_r_bear']}, b1_buy: {last_row_sg['b1_buy']}, b2_buy: {last_row_sg['b2_buy']},\n",
    "    b2_strong_buy: {last_row_sg['b2_strong_buy']}, s1_sell: {last_row_sg['s1_sell']}, s2_sell: {last_row_sg['s2_sell']},\n",
    "    s2_strong_sell: {last_row_sg['s2_strong_sell']}, signal: {last_row_sg['signal']}\n",
    "    \"\"\"\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"{'.'*5} Pivotpoints {'.'*5}\")\n",
    "    output += f\"{'.'*5} Pivotpoints {'.'*5}\\n\"\n",
    "    data = pd.read_csv(files) # Initialize the strategy class \n",
    "    pivot_points_strategy = PivotPoints() # Generate signals \n",
    "    data_with_signals = pivot_points_strategy.generate_signals(data) # Plot signals \n",
    "    #pivot_points_strategy.plot_signals(data_with_signals)\n",
    "    data_with_signals.drop(columns=['time.1', 'open', 'high', 'low', 'close', 'tick_volume', 'real_volume'], inplace=True)\n",
    "    print(data_with_signals.iloc[-1])\n",
    "    output += f\"{data_with_signals.iloc[-1]}\"\n",
    "    print(f\"{'*'*10} Machine Learning Models {'*'*10}\")\n",
    "    output += f\"{'*'*10} Machine Learning Models {'*'*10}\\n\"\n",
    "    data = pd.read_csv(f'{files}')\n",
    "    all_predictions_high = []\n",
    "    all_predictions_low = []\n",
    "    all_predictions_close = []\n",
    "    \n",
    "    # Initialize lists to collect all predictions\n",
    "    all_predictions_high = []\n",
    "    all_predictions_low = []\n",
    "    all_predictions_close = []\n",
    "    # Ridge Model\n",
    "    print(\"RidgeModel\")\n",
    "    output += \"RidgeModel\\n\"\n",
    "    prediction_high, prediction_low, prediction_close = RidgeModel(data)\n",
    "    # Ensure predictions are the same length as the data\n",
    "    prediction_high = [prediction_high[-1]] * len(data.index)\n",
    "    prediction_low = [prediction_low[-1]] * len(data.index)\n",
    "    prediction_close = [prediction_close[-1]] * len(data.index)\n",
    "    output += f\"Prediction High: {prediction_high[-1]}, Low: {prediction_low[-1]}, Close: {prediction_close[-1]}\\n\"\n",
    "    all_predictions_high.append(prediction_high[-1])\n",
    "    all_predictions_low.append(prediction_low[-1])\n",
    "    all_predictions_close.append(prediction_close[-1])\n",
    "\n",
    "    # Decision Tree\n",
    "    print(\"DecisionTree\")\n",
    "    output += \"DecisionTree\\n\"\n",
    "    prediction_high, prediction_low, prediction_close = DecisionTree(data)\n",
    "    # Ensure predictions are the same length as the data\n",
    "    prediction_high = [prediction_high[-1]] * len(data.index)\n",
    "    prediction_low = [prediction_low[-1]] * len(data.index)\n",
    "    prediction_close = [prediction_close[-1]] * len(data.index)\n",
    "    output += f\"Prediction High: {prediction_high[-1]}, Low: {prediction_low[-1]}, Close: {prediction_close[-1]}\\n\"\n",
    "    all_predictions_high.append(prediction_high[-1])\n",
    "    all_predictions_low.append(prediction_low[-1])\n",
    "    all_predictions_close.append(prediction_close[-1])\n",
    "   \n",
    "    # Linear Regression Model\n",
    "    print(\"LinearRegressionModel\")\n",
    "    output += \"LinearRegressionModel\\n\"\n",
    "    prediction_high, prediction_low, prediction_close = LinearRegressionModel(data)\n",
    "    # Ensure predictions are the same length as the data\n",
    "    prediction_high = [prediction_high[-1]] * len(data.index)\n",
    "    prediction_low = [prediction_low[-1]] * len(data.index)\n",
    "    prediction_close = [prediction_close[-1]] * len(data.index)\n",
    "    output += f\"Prediction High: {prediction_high[-1]}, Low: {prediction_low[-1]}, Close: {prediction_close[-1]}\\n\"\n",
    "    all_predictions_high.append(prediction_high[-1])\n",
    "    all_predictions_low.append(prediction_low[-1])\n",
    "    all_predictions_close.append(prediction_close[-1])\n",
    "  \n",
    "    # Bagging\n",
    "    print(\"Bagging\")\n",
    "    output += \"Bagging\\n\"\n",
    "    prediction_high, prediction_low, prediction_close = Bagging_Simple(data)\n",
    "    # Ensure predictions are the same length as the data\n",
    "    prediction_high = [prediction_high[-1]] * len(data.index)\n",
    "    prediction_low = [prediction_low[-1]] * len(data.index)\n",
    "    prediction_close = [prediction_close[-1]] * len(data.index)\n",
    "    output += f\"Prediction High: {prediction_high[-1]}, Low: {prediction_low[-1]}, Close: {prediction_close[-1]}\\n\"\n",
    "    all_predictions_high.append(prediction_high[-1])\n",
    "    all_predictions_low.append(prediction_low[-1])\n",
    "    all_predictions_close.append(prediction_close[-1])\n",
    "   \n",
    "   \n",
    "    # Aggregate predictions\n",
    "    avg_prediction_high = np.mean(all_predictions_high)\n",
    "    avg_prediction_low = np.mean(all_predictions_low)\n",
    "    avg_prediction_close = np.mean(all_predictions_close)\n",
    "    # Make a consolidated decision based on aggregated predictions\n",
    "    \n",
    "    print(\"\\n********** GARCH Model Volatility Prediction **********\")\n",
    "    arch_models = ArchModels(data)\n",
    "    arch_models.fit_models()\n",
    "    low_threshold_values = np.arange(0.5, 1.0, 0.1)\n",
    "    high_threshold_values = np.arange(1.0, 2.0, 0.1)\n",
    "    best_model, best_low_threshold, best_high_threshold, best_cumulative_return = arch_models.find_best_model_and_thresholds(low_threshold_values, high_threshold_values)\n",
    "    forecast_volatility = arch_models.garch_model_fit.forecast(horizon=5)\n",
    "    forecast = forecast_volatility.variance.iloc[-1].values\n",
    "    current_price = data['close'].iloc[-1]\n",
    "    action, position_size = arch_models.trading_strategy_with_optimized_thresholds(forecast, current_price, best_low_threshold, best_high_threshold)\n",
    "    print(f\"Action: {action}, Position Size: {position_size}, Forecasted Volatility for next 1 period: {forecast[0]}\")\n",
    "    output += \"\\n********** GARCH Model Volatility Prediction **********\"\n",
    "    output += f\"Action: {action}\\n\"\n",
    "    output += f\"Position Size: {position_size}\\n\"\n",
    "    output += f\"Forecasted Volatility for next 1 period: {forecast[0]}\\n\"\n",
    "    # Trend Direction and Strength\n",
    "    print(\"\\n********** Trend Direction and Strength **********\")\n",
    "    trend, volume_strength, support_level, resistance_level = analyze_market_trend(data, lookback_period=20, atr_period=14)\n",
    "    print(f\"Trend: {trend}, Volume Strength: {volume_strength}, Support: {support_level}, Resistance: {resistance_level}\")\n",
    "    output += \"\\n********** Trend Direction and Strength **********\\n\"\n",
    "    output += f\"Trend: {trend}, Volume Strength: {volume_strength}, Support: {support_level}, Resistance: {resistance_level}\\n\"\n",
    "    output += f\"Current High: {current_high}, Close: {current_close}, Low: {current_low}\\n\"\n",
    "    full_text = output\n",
    "    \n",
    "        \n",
    "    \n",
    "     # Write to file and print\n",
    "    current_time = datetime.now().strftime(\"%d%b%H%M\")\n",
    "    filename = f\"{symbol}_analysis_{current_time}.txt\"\n",
    "    print(filename)\n",
    "    write_output_to_file(output, filename)\n",
    " # Write to file and print\n",
    "    \n",
    "filename = f\"{symbol}_analysis_FULL.txt\"\n",
    "print(filename)\n",
    "write_output_to_file(full_text, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206f68dd-3732-4ae6-a5f1-9c30004eba7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allworks",
   "language": "python",
   "name": "allworks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
